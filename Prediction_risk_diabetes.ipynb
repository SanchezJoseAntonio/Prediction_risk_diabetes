{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY5bsVFdNMtHNAu5jJdKeJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanchezJoseAntonio/Prediction_risk_diabetes/blob/main/Prediction_risk_diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.inspection import permutation_importance\n",
        "from lightgbm import LGBMRegressor"
      ],
      "metadata": {
        "id": "k4ITBhdFTwIM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"diabetes.csv\"\n",
        "# Load the latest version\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"uciml/pima-indians-diabetes-database\",\n",
        "  file_path,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "qsR9My2nM9hc",
        "outputId": "807da668-7764-48ba-e584-4991087863c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-4013140087.py, line 6)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4013140087.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    file_path,\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "m_gH8dWrRRUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "XmhIboj8cvNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "--mHL4uKRVTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "BSUR7d3vcpV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of this data is biologically impossible. There is a minimum of 0 for SkinThickness, bloodpressure... This means that at least one observation has these values. These are clearly incorrect.\n"
      ],
      "metadata": {
        "id": "K5CoZ2jOeZQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "6n7KszXqfk7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(df[\"BloodPressure\"]);"
      ],
      "metadata": {
        "id": "n1YvhY_hfEQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"BloodPressure\"] < 40].head(5)"
      ],
      "metadata": {
        "id": "TKl8qroPfFuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's clear that there are missing values, that are just represented as 0. I'll now change them to NA for easier retrieval. I will update the columns that have 0 as a minimum and are continuous."
      ],
      "metadata": {
        "id": "vNcx5zOkhXH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"Glucose\",\t\"BloodPressure\",\t\"SkinThickness\",\t\"Insulin\",\t\"BMI\"]\n",
        "df[cols]=df[cols].replace(0, np.nan)"
      ],
      "metadata": {
        "id": "m3ylCACNhV-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "Co8KQ4gZe_aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The amount of missing values for skin thickness and insulin are very high. However, insulin is highly related to diabetes, and skin thickness is highly related to obesity, a major factor in diabetes. Therefore, I will not drop these features.\n",
        "\n",
        "\n",
        "On the other hand, missingness can be informative (e.g they may or may not have done the test for a reason). This is why for insulin and skin thickness I will add a column regarding whether the value was missing or not. This will assure that this information can be evaluated by the algorithm later on, even after handling the missing values."
      ],
      "metadata": {
        "id": "SxNdFLMPosj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Insulin_NA\"]=df['Insulin'].isna().astype('category')\n",
        "df[\"SkinThickness_NA\"]=df['SkinThickness'].isna().astype('category')\n",
        "df[\"Missing_Total\"]=df.isna().sum(axis=1)\n",
        "df[\"Missing_Total\"].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "_ZECF6mOm48j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df.index[df[\"Missing_Total\"]>3],axis=0, inplace=True) #Delete rows where there are more than 3 missing values.\n",
        "df.drop(\"Missing_Total\",axis=1,inplace=True)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "jQDC1hxpGdDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.copy()"
      ],
      "metadata": {
        "id": "EJTRzGGwGZ65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "jZ0XvsXsJgg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df, hue=\"Outcome\");"
      ],
      "metadata": {
        "id": "gEgCORSmwxsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling missing data: replacing by median\n",
        "I will substitute the missing values by the median in each case. I will first divide the dataset in training and test data so there is no data leakage."
      ],
      "metadata": {
        "id": "OhGzh0T27dup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(labels=\"Outcome\",axis=1)\n",
        "y = df[\"Outcome\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "cols = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
        "\n",
        "for col in cols:\n",
        "  X_train[col]=X_train[col].replace(np.nan, X_train[col].median())\n",
        "  X_test[col]=X_test[col].replace(np.nan, X_train[col].median()) # Imputing for the test with the training data"
      ],
      "metadata": {
        "id": "OmVwiI5tySLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.isna().sum()"
      ],
      "metadata": {
        "id": "dS-d75kG9Yxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking feature importance\n",
        "I will evaluate feature importance through a random forest. This can help me figure out if any features are irrelevant and simplify the model. Because impurity importance can bias the results, I will use permutation importance."
      ],
      "metadata": {
        "id": "LDzL1BvBtCE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imp_rf(X_train, X_test, y_train, y_test, random_state=25, n_estimators=200, class_weight = \"balanced\"):\n",
        "  rf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state, class_weight=class_weight)\n",
        "  model =rf.fit(X_train, y_train)\n",
        "  result = permutation_importance(model, X_train, y_train, n_repeats=10,random_state=random_state)\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "L6O6O1QAtywN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranking = pd.DataFrame(zip(df.drop(columns=['Outcome']).columns, imp_rf(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test).importances_mean))\n",
        "ranking.sort_values(by=1, axis=0)"
      ],
      "metadata": {
        "id": "CD4EzpoA1AMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Surprisingly, the columns that represent missing values for skin thickness and insulin have a permutation importance of 0 or almost 0. This is because during the pre-processing, I substituted the NA values for the median. The trees are adjusting by using the information from the median in the insulin column instead of from the missing values column.\n",
        "\n"
      ],
      "metadata": {
        "id": "7Rr5qw9h759K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling missing data with lightgbm\n",
        "I will now proceed to use lightgbm to handle the missing data. It will infer the data that should be in the missing values.\n",
        "To avoid data leakage, I will separate the test and training data, and apply the model to both of them."
      ],
      "metadata": {
        "id": "1ERaF3ylLIWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2[\"NA_Total\"]=df2.isna().sum(axis=1)\n",
        "df2.isna().sum()"
      ],
      "metadata": {
        "id": "byHKaRXM-pho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the previous data, I know glucose and BMI have specially high importances so the imputation of these two variables is of special relevance. I can also see that the missing values from  them are 5 and 4 rows respectively. Let's examine them closely"
      ],
      "metadata": {
        "id": "vnDvc7vzJSou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2[df2[\"BMI\"].isna()]"
      ],
      "metadata": {
        "id": "5-r5HekWJ2km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2[df2[\"Glucose\"].isna()]"
      ],
      "metadata": {
        "id": "KRYtizqqJ2Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I see two observations in BMI that contain 3 missing values. I will drop these as they can introduce noise in the model."
      ],
      "metadata": {
        "id": "8ok8t5uhMx0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.drop([9,684], axis=0, inplace=True)\n",
        "df2.drop(\"NA_Total\", axis=1, inplace=True)\n",
        "df2[df2[\"BMI\"].isna()]"
      ],
      "metadata": {
        "id": "ajJSdntkNJdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will start imputing the rest of the missing values.Therefore I will divide the data in training and test data"
      ],
      "metadata": {
        "id": "wonBvRorXvwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df2.drop(labels=\"Outcome\",axis=1)\n",
        "y = df2[\"Outcome\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=33, stratify=y)"
      ],
      "metadata": {
        "id": "28R9ucsAN1fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "na_cols = X_train.isna().sum()\n",
        "na_cols = na_cols[na_cols > 0 ].sort_values() #Sorting the values from the least amount of NAs to the most, so the ones with the most can use more information\n",
        "na_cols"
      ],
      "metadata": {
        "id": "dT0PrU4tYV44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df2.drop(labels=\"Outcome\",axis=1)\n",
        "y = df2[\"Outcome\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=33, stratify=y)\n",
        "for col in na_cols:\n"
      ],
      "metadata": {
        "id": "_qC-sebUacsO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}